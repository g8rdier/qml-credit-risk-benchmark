{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classical SVM Exploration - BI2 Project\n",
    "\n",
    "This notebook provides an interactive environment for exploring the classical SVM implementation.\n",
    "\n",
    "**Objectives:**\n",
    "1. Load and explore the German Credit Risk dataset\n",
    "2. Understand the preprocessing pipeline\n",
    "3. Train and evaluate classical SVM models\n",
    "4. Compare different kernels and hyperparameters\n",
    "5. Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add parent directory to path\n",
    "sys.path.insert(0, str(Path.cwd().parent / 'src'))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✅ Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Loading\n",
    "\n",
    "Load the German Credit Risk dataset from OpenML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_loader import CreditDataLoader\n",
    "\n",
    "# Load data\n",
    "loader = CreditDataLoader()\n",
    "X, y = loader.load_from_openml()\n",
    "\n",
    "print(f\"\\nDataset shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nTarget distribution:\\n{y.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore the data\n",
    "print(\"First few rows:\")\n",
    "display(X.head())\n",
    "\n",
    "print(\"\\nData types:\")\n",
    "print(X.dtypes)\n",
    "\n",
    "print(\"\\nData summary:\")\n",
    "summary = loader.get_data_summary()\n",
    "for key, value in summary.items():\n",
    "    if key != 'feature_names':\n",
    "        print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing\n",
    "\n",
    "Apply the complete preprocessing pipeline:\n",
    "- Missing value handling\n",
    "- Categorical encoding\n",
    "- Scaling\n",
    "- PCA dimensionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import CreditDataPreprocessor\n",
    "\n",
    "# Initialize preprocessor with 4 components (for 4-qubit QSVM later)\n",
    "preprocessor = CreditDataPreprocessor(n_components=4)\n",
    "\n",
    "# Run preprocessing pipeline\n",
    "X_train, X_test, y_train, y_test = preprocessor.preprocess_data(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize PCA results\n",
    "explained_var = preprocessor.pca.explained_variance_ratio_\n",
    "cumulative_var = np.cumsum(explained_var)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Explained variance per component\n",
    "ax1.bar(range(1, len(explained_var) + 1), explained_var, alpha=0.7, color='steelblue')\n",
    "ax1.set_xlabel('Principal Component')\n",
    "ax1.set_ylabel('Explained Variance Ratio')\n",
    "ax1.set_title('Explained Variance by Component')\n",
    "ax1.set_xticks(range(1, len(explained_var) + 1))\n",
    "\n",
    "# Cumulative explained variance\n",
    "ax2.plot(range(1, len(cumulative_var) + 1), cumulative_var, marker='o', linewidth=2, color='steelblue')\n",
    "ax2.axhline(y=0.8, color='r', linestyle='--', alpha=0.5, label='80% threshold')\n",
    "ax2.set_xlabel('Number of Components')\n",
    "ax2.set_ylabel('Cumulative Explained Variance')\n",
    "ax2.set_title('Cumulative Explained Variance')\n",
    "ax2.legend()\n",
    "ax2.grid(alpha=0.3)\n",
    "ax2.set_xticks(range(1, len(cumulative_var) + 1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Total explained variance with {len(explained_var)} components: {cumulative_var[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize data in reduced space (first 2 PCs)\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, cmap='RdYlGn', alpha=0.6, edgecolors='k', s=50)\n",
    "plt.xlabel(f'PC1 ({explained_var[0]:.2%} variance)')\n",
    "plt.ylabel(f'PC2 ({explained_var[1]:.2%} variance)')\n",
    "plt.title('Training Data in PCA Space (First 2 Components)')\n",
    "plt.colorbar(scatter, label='Credit Quality (0=Bad, 1=Good)')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classical SVM Training\n",
    "\n",
    "Train a classical SVM with RBF kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classical_svm import ClassicalSVM\n",
    "\n",
    "# Initialize and train\n",
    "svm = ClassicalSVM(kernel='rbf', C=1.0)\n",
    "svm.train(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "metrics = svm.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate detailed report\n",
    "report = svm.generate_classification_report(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "svm.plot_confusion_matrix(X_test, y_test, save_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve\n",
    "svm.plot_roc_curve(X_test, y_test, save_path=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Kernel Comparison\n",
    "\n",
    "Compare different SVM kernels to find the best performing one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classical_svm import compare_kernels\n",
    "\n",
    "# Compare kernels\n",
    "comparison_df = compare_kernels(X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Display results\n",
    "display(comparison_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize kernel comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "metrics_to_plot = ['accuracy', 'precision', 'recall', 'f1_score']\n",
    "colors = ['steelblue', 'coral', 'lightgreen', 'plum']\n",
    "\n",
    "for ax, metric, color in zip(axes.flat, metrics_to_plot, colors):\n",
    "    bars = ax.bar(comparison_df['kernel'], comparison_df[metric], color=color, alpha=0.7, edgecolor='black')\n",
    "    ax.set_ylabel(metric.replace('_', ' ').title())\n",
    "    ax.set_xlabel('Kernel')\n",
    "    ax.set_ylim([0, 1])\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.3f}',\n",
    "                ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "plt.suptitle('Kernel Performance Comparison', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Hyperparameter Impact\n",
    "\n",
    "Explore how different hyperparameters affect performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different C values\n",
    "C_values = [0.1, 1.0, 10.0, 100.0]\n",
    "results = []\n",
    "\n",
    "for C in C_values:\n",
    "    print(f\"\\nTesting C={C}...\")\n",
    "    svm_temp = ClassicalSVM(kernel='rbf', C=C)\n",
    "    svm_temp.train(X_train, y_train)\n",
    "    metrics = svm_temp.evaluate(X_test, y_test)\n",
    "    results.append({'C': C, **metrics})\n",
    "\n",
    "df_C = pd.DataFrame(results)\n",
    "display(df_C[['C', 'accuracy', 'precision', 'recall', 'f1_score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize C parameter impact\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "ax.plot(df_C['C'], df_C['accuracy'], marker='o', label='Accuracy', linewidth=2)\n",
    "ax.plot(df_C['C'], df_C['precision'], marker='s', label='Precision', linewidth=2)\n",
    "ax.plot(df_C['C'], df_C['recall'], marker='^', label='Recall', linewidth=2)\n",
    "ax.plot(df_C['C'], df_C['f1_score'], marker='D', label='F1-Score', linewidth=2)\n",
    "\n",
    "ax.set_xscale('log')\n",
    "ax.set_xlabel('C (Regularization Parameter)', fontsize=12)\n",
    "ax.set_ylabel('Score', fontsize=12)\n",
    "ax.set_title('Impact of C Parameter on Model Performance', fontsize=14, fontweight='bold')\n",
    "ax.legend(loc='best')\n",
    "ax.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Feature Space Analysis\n",
    "\n",
    "Understand how PCA component count affects performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different numbers of components\n",
    "component_counts = [2, 4, 6, 8, 10]\n",
    "pca_results = []\n",
    "\n",
    "for n_comp in component_counts:\n",
    "    print(f\"\\nTesting {n_comp} components...\")\n",
    "    \n",
    "    # Preprocess with different component count\n",
    "    prep_temp = CreditDataPreprocessor(n_components=n_comp)\n",
    "    X_tr, X_te, y_tr, y_te = prep_temp.preprocess_data(X, y)\n",
    "    \n",
    "    # Train and evaluate\n",
    "    svm_temp = ClassicalSVM(kernel='rbf')\n",
    "    svm_temp.train(X_tr, y_tr)\n",
    "    metrics = svm_temp.evaluate(X_te, y_te)\n",
    "    \n",
    "    pca_results.append({\n",
    "        'n_components': n_comp,\n",
    "        'explained_variance': prep_temp.pca.explained_variance_ratio_.sum(),\n",
    "        **metrics\n",
    "    })\n",
    "\n",
    "df_pca = pd.DataFrame(pca_results)\n",
    "display(df_pca[['n_components', 'explained_variance', 'accuracy', 'f1_score', 'training_time']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize PCA component count impact\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Accuracy vs components\n",
    "ax1_twin = ax1.twinx()\n",
    "line1 = ax1.plot(df_pca['n_components'], df_pca['accuracy'], marker='o', color='steelblue', linewidth=2, label='Accuracy')\n",
    "line2 = ax1_twin.plot(df_pca['n_components'], df_pca['explained_variance'], marker='s', color='coral', linewidth=2, label='Explained Variance')\n",
    "ax1.set_xlabel('Number of PCA Components')\n",
    "ax1.set_ylabel('Accuracy', color='steelblue')\n",
    "ax1_twin.set_ylabel('Explained Variance', color='coral')\n",
    "ax1.set_title('Accuracy vs PCA Components')\n",
    "ax1.grid(alpha=0.3)\n",
    "lines = line1 + line2\n",
    "labels = [l.get_label() for l in lines]\n",
    "ax1.legend(lines, labels, loc='best')\n",
    "\n",
    "# Training time vs components\n",
    "ax2.plot(df_pca['n_components'], df_pca['training_time'], marker='o', color='green', linewidth=2)\n",
    "ax2.set_xlabel('Number of PCA Components')\n",
    "ax2.set_ylabel('Training Time (seconds)')\n",
    "ax2.set_title('Training Time vs PCA Components')\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary and Next Steps\n",
    "\n",
    "### Key Findings\n",
    "- Best kernel: [To be determined from results]\n",
    "- Optimal C value: [To be determined from results]\n",
    "- PCA components trade-off: [To be determined from results]\n",
    "\n",
    "### Next Steps for BI2 Project\n",
    "1. Implement Quantum SVM (QSVM) using Qiskit\n",
    "2. Compare QSVM performance with Classical SVM\n",
    "3. Analyze computational cost differences\n",
    "4. Test on different component counts (qubit counts)\n",
    "5. Generate final comparison report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model and preprocessor for later use\n",
    "svm.save_model(\"../models/classical_svm_rbf.pkl\")\n",
    "preprocessor.save_preprocessor(\"../models/preprocessor_4comp.pkl\")\n",
    "\n",
    "print(\"✅ Models saved successfully!\")\n",
    "print(\"\\nReady to proceed with Quantum SVM implementation.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
